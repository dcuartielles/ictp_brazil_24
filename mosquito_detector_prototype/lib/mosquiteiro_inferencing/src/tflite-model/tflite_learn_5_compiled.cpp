/*
 * Copyright (c) 2024 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://docs.edgeimpulse.com/page/terms-of-service) or Enterprise Terms of
 * Service (https://docs.edgeimpulse.com/page/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */
// Generated on: 25.07.2024 19:07:01

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined (__GNUC__)  /* GNU compiler */
#define ALIGN(X) __attribute__((aligned(X)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (_MSC_VER)
#define ALIGN(X) __declspec(align(X))
#elif defined (__TASKING__) /* TASKING Compiler */
#define ALIGN(X) __align(X)
#define DEFINE_SECTION(x) __attribute__(section(x)))
#elif defined (__ARMCC_VERSION) /* Arm Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ICCARM__) /* IAR Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__clang__) /* LLVM/Clang Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 8
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 15392;
#else
constexpr int kTensorArenaSize = 14368;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
#if defined (EI_TENSOR_ARENA_LOCATION)
#define STRINGIZE(x) #x
#define STRINGIZE_VALUE_OF(x) STRINGIZE(x)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) DEFINE_SECTION(STRINGIZE_VALUE_OF(EI_TENSOR_ARENA_LOCATION));
#else
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#endif
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};

enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};

struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];

namespace g0 {
const TfArray<2, int> tensor_dimension0 = { 2, { 1,6435 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0095718381926417351, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 99, 65, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 99, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 50, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 50, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 400, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(8) int32_t tensor_data6[2] = { -3347, 3347, };
const TfArray<1, int> tensor_dimension6 = { 1, { 2 } };
const TfArray<1, float> quant6_scale = { 1, { 0.00065533473389223218, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[2*400] = { 
  13, 1, 4, 2, 0, 11, -7, 8, 32, 0, 6, -4, -3, 4, 4, 0, 9, 5, 6, -5, 2, 1, -2, 12, 33, -13, 25, 0, 2, -9, 1, 6, 26, 57, 9, 4, 11, 53, 49, 15, 91, -8, 6, 60, 5, 17, 4, 16, 25, 62, 11, 2, 12, 53, 0, 0, 46, -19, 37, 52, 4, 10, 0, 7, 66, 40, 8, 8, 12, 96, 58, 17, 77, -13, 86, 120, 3, 15, -1, 10, 39, 18, 7, 10, 2, 17, 62, 8, 15, -20, 22, 46, 13, -5, -5, 4, 11, 22, 8, 0, 2, 9, 10, 5, -13, 0, -39, -7, -4, 3, -4, -3, -4, 36, 1, 22, 2, 5, -56, -2, 24, -16, -4, 31, 14, -3, 13, -3, 44, 66, 6, 11, 6, 26, 29, 4, 48, -6, -2, 31, 13, 6, 1, 10, 9, 30, 2, 7, 8, 44, 26, 3, 65, -12, 29, 47, 9, 8, -5, 5, 27, 46, 2, 5, 12, 60, 26, 4, 30, -12, 53, 14, 8, 2, 9, 9, 24, 18, 13, 7, 10, 46, 36, 3, 71, -18, 53, 73, 3, -7, 1, -2, 34, 43, 15, 4, 9, 44, 7, 0, 21, -14, 3, 44, 6, 15, 5, 8, 16, 55, 13, 11, 9, 95, 21, 5, 60, -7, 45, 34, 9, 3, 9, 5, 32, 17, 7, 1, 7, 95, 54, 2, 47, -7, -1, 10, 8, -5, 2, 15, 26, 56, -3, 2, 11, 53, 0, -1, 40, -13, 27, 83, 4, 14, 0, 7, 85, 36, 4, 5, 6, 100, 23, 7, 9, -11, -2, 50, 8, 15, 6, 1, 43, 24, 8, 10, 11, 59, 51, 10, 33, -12, 33, 67, 6, 1, 9, 12, 47, 20, 2, 5, 13, 2, 42, 7, 6, -10, -2, 26, 5, 16, 1, 15, 23, 30, 12, 6, 9, 13, 19, -1, 62, -14, -2, 17, 9, -3, 10, 2, 8, 23, 4, 3, 9, 6, 43, 2, 17, -10, 50, 47, 13, -1, 5, 11, 8, 50, -4, 8, 15, 57, 22, 1, 62, -6, 22, 59, 16, 17, 10, 10, 14, 57, 7, 8, 11, -2, 56, 2, 31, -5, 36, 54, 1, -2, 9, 7, 40, 14, 13, 5, 8, 0, 50, 2, 6, -10, 28, 40, 4, -1, 4, 6, 22, 20, -7, 11, 20, 24, 8, 0, 12, -10, 3, 84, 3, 16, 3, 12, 
  -5, -5, -1, 2, 1, -15, -1, -11, -36, 6, -16, -4, -3, 6, -3, 1, -5, -6, -2, -5, 5, 0, 3, -7, -31, 7, -20, -3, 1, 17, -4, 6, -24, -50, -5, -12, -14, -65, -43, -5, -94, 18, -12, -61, -9, -11, -10, -18, -19, -66, -8, -11, -9, -54, 9, -5, -50, 8, -28, -47, -6, -14, -8, -9, -64, -38, -8, -7, -14, -94, -64, -18, -75, 14, -91, -127, -9, -16, 2, -12, -42, -20, -10, -9, -3, -22, -57, -9, -17, 21, -18, -44, -15, 1, -4, -3, -5, -16, 1, 0, 5, -8, -10, -1, 9, 6, 32, 12, -3, -6, 3, -2, 3, -30, -4, -16, 6, -6, 56, -10, -28, 6, 5, -27, -8, -4, -4, -4, -47, -64, -11, -7, -5, -21, -23, -8, -55, 7, 1, -26, -5, -5, -7, -7, -14, -36, -5, 0, -5, -35, -34, 2, -63, 5, -24, -50, -8, -6, -1, -11, -32, -48, -4, -2, -17, -65, -21, 6, -33, 14, -61, -11, -7, -4, -4, -11, -16, -20, -5, -4, -7, -46, -38, -5, -75, 7, -55, -78, -5, 9, -11, -10, -35, -44, -11, -12, -3, -47, -5, -3, -23, 11, 0, -51, -5, -25, -10, -8, -21, -53, -8, -2, -16, -91, -26, -7, -66, 10, -47, -32, -2, 4, -7, -5, -31, -11, -5, -10, -11, -104, -47, -5, -44, 6, 1, -22, -9, 7, -7, -13, -19, -56, 9, -9, -2, -50, 2, 0, -40, 19, -27, -88, -8, -9, -4, -15, -84, -32, 3, -8, -15, -92, -29, -5, -9, 13, -6, -44, 0, -11, -3, -10, -41, -22, -4, -6, -9, -58, -52, -7, -34, 10, -42, -63, -2, 0, -9, -4, -44, -8, -7, -9, -6, -5, -32, 1, -6, 10, 13, -15, -9, -7, -2, -10, -25, -27, -8, -11, -8, -7, -17, -5, -58, 4, -4, -26, 3, -1, -5, -10, -6, -35, -1, -10, -5, -3, -40, -3, -20, 13, -52, -43, -7, 1, -3, -8, -19, -50, 8, -8, -7, -55, -19, -8, -64, 13, -27, -67, -4, -8, -15, -10, -7, -47, -2, -7, -16, 1, -58, -4, -32, 9, -28, -56, -7, 6, -3, -10, -40, -14, -7, -6, -14, 4, -49, -1, 3, 19, -17, -36, -10, -5, -5, -9, -17, -25, 6, -13, -12, -25, -18, 0, -13, 11, -7, -77, -7, -15, 4, -12, 
};
const TfArray<2, int> tensor_dimension7 = { 2, { 2,400 } };
const TfArray<1, float> quant7_scale = { 1, { 0.018790010362863541, } };
const TfArray<1, int> quant7_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int32_t tensor_data8[16] = { -1803, -1391, -622, -482, -47, -1874, -1050, -381, -1924, 116, -1427, -1910, -270, -222, -413, -110, };
const TfArray<1, int> tensor_dimension8 = { 1, { 16 } };
const TfArray<16, float> quant8_scale = { 16, { 0.001388859236612916, 0.0018223264487460256, 0.0061428053304553032, 0.0019121749792248011, 0.0047783674672245979, 0.0019119697390124202, 0.0020573639776557684, 0.0013175016501918435, 0.0015960693126544356, 0.0053841890767216682, 0.0017723884666338563, 0.001257879426702857, 0.0032498296350240707, 0.0037682936526834965, 0.00070756988134235144, 0.0068813655525445938, } };
const TfArray<16, int> quant8_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int8_t tensor_data9[16*1*3*8] = { 
  /* [0][0][][] */ -16,-57,101,-82,-5,-15,-30,-78, -78,-18,63,-44,-74,-57,-127,-59, -10,-23,-25,-16,5,-44,6,32, 
  /* [1][0][][] */ -17,-37,55,-37,-24,-9,-79,27, -72,-73,-37,-106,2,-19,-24,-11, -24,-46,-37,-127,-3,-14,-43,-29, 
  /* [2][0][][] */ -1,-5,6,4,-3,-3,-29,-25, 5,-1,-45,-127,-44,-6,15,-8, 2,-13,12,2,-3,-12,-11,11, 
  /* [3][0][][] */ 13,3,-73,-51,-76,-36,17,15, 0,16,57,-22,-41,20,-17,40, 5,-2,-5,-52,-23,11,-21,-127, 
  /* [4][0][][] */ 1,2,-10,-127,-25,-10,-43,-17, -29,3,-3,-42,-29,-36,-37,-30, 2,4,-6,-70,-28,-51,-65,-36, 
  /* [5][0][][] */ -59,-18,12,-19,-24,-127,7,-47, -64,-25,6,-7,-65,-63,-3,26, -68,-6,35,-14,-44,-24,-16,-71, 
  /* [6][0][][] */ -12,-55,89,-39,-28,-67,26,-47, 0,-63,10,-23,-5,-91,-82,0, -1,-53,-19,-127,-26,-86,-63,-74, 
  /* [7][0][][] */ -110,-4,58,4,17,36,45,37, -81,-8,-11,7,15,30,35,-23, -100,-6,-127,0,-22,-12,41,32, 
  /* [8][0][][] */ -37,-76,8,-58,11,35,24,-60, -63,-51,107,-81,-10,-127,-5,22, -66,-111,43,1,-32,-59,-28,28, 
  /* [9][0][][] */ -2,-109,-17,-50,-34,-21,-54,-35, -3,-94,-28,-56,-44,-45,-69,-41, -3,-127,-46,-53,-17,16,-34,6, 
  /* [10][0][][] */ -52,-13,35,-52,-33,-34,-46,-91, -19,-11,-27,-57,-42,-56,-60,-127, -31,-6,20,-26,-36,-67,-55,27, 
  /* [11][0][][] */ -39,-56,15,-104,20,11,20,88, -116,-73,-9,-59,-99,-25,-81,36, -59,-39,127,-16,-22,-20,8,-45, 
  /* [12][0][][] */ 1,0,-47,-127,-43,-36,-100,5, 6,7,-1,-26,-67,-9,11,-18, 1,-1,-14,-14,-6,-27,2,-18, 
  /* [13][0][][] */ -7,-3,-2,-127,-3,-14,-43,-33, -29,-14,8,-40,-5,-20,-34,-11, 1,-3,-15,-7,-17,-24,-36,-12, 
  /* [14][0][][] */ -13,-32,-2,-85,-4,-28,-50,-74, -127,-8,-22,-25,-59,-46,-16,-91, -40,-86,-28,-16,-87,-106,-89,-64, 
  /* [15][0][][] */ 2,3,17,-127,-43,-38,-4,-18, 1,2,0,-74,-16,-9,-8,-23, 2,2,-22,-105,-29,-10,-4,-22, 
};
const TfArray<4, int> tensor_dimension9 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant9_scale = { 16, { 0.008624623529613018, 0.011316395364701748, 0.038145970553159714, 0.01187434233725071, 0.029673000797629356, 0.011873067356646061, 0.012775946408510208, 0.0081815030425786972, 0.0099113695323467255, 0.033435069024562836, 0.011006287299096584, 0.0078112571500241756, 0.020180992782115936, 0.023400582373142242, 0.0043939109891653061, 0.042732328176498413, } };
const TfArray<16, int> quant9_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int32_t tensor_data10[8] = { -66569, 42353, -41388, -12817, -14446, -924, -18072, -27655, };
const TfArray<1, int> tensor_dimension10 = { 1, { 8 } };
const TfArray<8, float> quant10_scale = { 8, { 0.00011252972763031721, 0.00016945278912317008, 0.00016267086903098971, 0.00016563254757784307, 0.0001841087214415893, 0.00014435945195145905, 0.00016115340986289084, 0.00016178163059521466, } };
const TfArray<8, int> quant10_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(16) int8_t tensor_data11[8*1*3*65] = { 
  /* [0][0][][] */ 0,91,-11,-60,22,-86,-74,-57,-63,-57,-32,-32,-56,-32,-26,-23,-15,-20,-26,-25,-18,-12,-8,-11,7,26,29,34,34,35,36,35,38,40,41,39,37,42,41,37,38,39,40,40,37,40,40,40,40,38,39,38,36,33,36,34,35,34,34,31,29,33,31,29,49, 12,127,8,-61,43,-90,-79,-44,-72,-65,-36,-38,-93,-78,-75,-59,-60,-73,-81,-80,-81,-84,-89,-93,-61,0,6,9,8,12,8,12,7,8,5,1,3,0,-2,-6,-13,-16,-22,-22,-29,-28,8,26,24,18,23,18,13,19,11,5,8,2,-1,-6,-3,-4,-5,-4,35, 3,84,-3,-63,25,-82,-74,-56,-60,-48,-30,-27,-48,-30,-18,-9,-7,-13,-16,-16,-14,-3,2,4,13,34,36,36,39,43,38,41,46,43,46,45,46,45,46,49,48,45,49,46,47,41,50,49,44,46,40,44,43,42,42,44,42,42,38,42,38,40,35,40,57, 
  /* [1][0][][] */ -21,48,-4,10,19,4,17,23,32,35,62,63,61,65,73,78,93,81,69,60,52,9,-45,-75,-72,-38,-44,-37,-55,-57,-52,-59,-71,-72,-71,-68,-87,-79,-88,-95,-98,-108,-111,-127,-126,-125,-87,-57,-47,-50,-46,-47,-46,-51,-55,-56,-63,-64,-64,-69,-58,-64,-62,-69,-33, -31,18,-29,-9,4,-15,0,2,17,19,39,30,40,50,43,52,60,51,46,40,30,18,4,-17,-11,2,8,2,3,3,-11,-7,-4,-2,3,-4,-7,-10,-5,-11,-9,-8,-17,-13,-12,-16,-6,-2,-2,-9,-11,-7,-6,-7,-11,-15,-8,-8,-11,-15,-22,-11,-11,-21,-1, -36,23,-21,-7,6,-10,2,2,1,20,37,42,49,55,56,60,61,56,47,47,42,35,5,-4,3,16,13,14,12,8,12,10,13,10,6,5,4,4,9,6,0,-2,-2,7,6,1,9,4,10,13,-1,7,1,0,0,8,3,0,4,-2,0,-4,-5,0,3, 
  /* [2][0][][] */ 18,-3,-26,8,1,-14,-83,-38,-58,-39,-16,-4,-9,55,39,75,30,32,14,-62,-8,3,10,-32,-15,-25,-4,1,27,-2,-11,26,18,-3,12,-34,18,-61,-6,-67,61,-63,17,39,21,-40,56,29,12,-70,-56,-17,-42,-38,-15,-1,-24,16,-29,15,-24,4,40,10,-2, 31,-14,20,36,-42,-8,-63,-69,-39,27,-11,-49,-29,-26,39,-14,13,-41,-28,-2,-4,-12,-13,19,77,25,-33,-88,-70,18,-71,68,-54,2,-19,24,33,-21,-26,7,-16,20,-47,-33,-22,14,85,49,-15,0,-30,-21,22,48,-11,11,24,-42,-54,-83,48,-106,-7,62,15, -25,-46,-50,-60,48,-22,-20,-42,-45,-25,1,13,7,-68,-69,99,52,22,68,-58,-71,48,-27,-43,-20,-50,31,29,48,-15,0,0,4,11,-16,51,-74,60,-61,-57,-29,-94,39,8,-72,40,-75,32,-12,-43,-50,-127,-18,30,-23,16,-18,33,13,22,-35,65,-24,45,-26, 
  /* [3][0][][] */ 35,65,1,-88,-10,-89,-57,-61,-68,-59,-48,-25,-52,-62,-8,-38,3,-37,-54,-54,-5,-35,-30,-37,-19,17,9,27,48,6,-19,-2,8,7,19,77,17,36,38,-11,-4,59,14,33,20,9,18,-4,85,37,53,55,5,35,43,6,18,48,-21,8,6,47,32,6,38, -70,-11,-54,-41,5,-41,-8,-90,2,-34,-6,-8,-17,-50,-39,-42,-30,-29,1,-8,-57,-41,9,-57,-68,-31,-85,-35,9,-76,-39,-75,-8,-30,14,-96,-82,-83,-63,-69,-2,15,-51,-29,-35,-42,-37,-40,-52,-10,-56,-58,-91,-11,-75,-17,-36,-38,-16,17,-31,-56,-24,-63,-10, 108,127,-5,-43,13,-92,-100,-89,-84,-68,-27,-22,-64,-55,-23,-31,-7,-23,-54,-36,-28,-17,-15,-12,4,47,50,45,36,29,37,14,36,73,53,48,6,23,41,42,63,10,26,35,37,22,51,49,64,75,42,70,34,68,36,45,57,42,30,32,27,70,-18,39,69, 
  /* [4][0][][] */ 20,17,-74,-54,14,33,-20,3,1,1,-53,-45,18,46,-51,-26,-21,48,3,-32,-87,17,-11,-54,12,-57,-28,35,-38,-43,29,-72,-40,-31,-51,-44,-43,-42,-53,-27,12,-62,11,-74,-108,-29,-105,-66,56,-80,-38,-55,-36,15,-54,16,11,24,55,-60,-39,-4,56,22,-19, -9,10,16,26,13,-56,-36,-42,-119,-13,31,-44,-36,-78,-42,-101,-17,-39,-85,-32,-12,-57,-29,-63,-127,-19,-15,-29,-32,-66,7,-72,98,-66,62,1,-64,19,-30,-75,-29,-38,14,3,0,3,-60,38,-70,-23,28,-36,43,-26,-38,4,-80,53,-5,-52,-79,-107,-23,7,20, 25,44,29,-4,-62,-12,-30,16,-49,-31,78,29,-28,-9,-2,-23,14,-21,71,-81,45,-17,-9,26,56,19,60,-61,0,-32,-24,-41,1,16,19,4,-42,15,-2,71,-38,48,43,4,-35,23,79,-6,31,41,48,37,29,26,73,-10,51,63,-31,23,19,24,2,50,-28, 
  /* [5][0][][] */ 0,-48,-69,-2,-58,-31,-49,-61,-8,-37,-63,-54,-12,-106,6,-71,-71,-4,-85,60,86,34,50,-19,-22,-2,-41,20,79,68,101,-33,-49,-83,96,50,39,-26,-59,-47,66,6,-5,19,-73,-108,35,-15,27,-87,19,17,-28,-41,-30,-11,-19,15,-84,-38,-66,-14,-37,-29,0, 58,-8,-10,21,50,97,-33,71,57,-66,-40,-78,0,-53,-1,1,-29,8,-83,-27,-124,126,-86,13,-64,-50,33,-52,-121,-20,-16,-36,37,20,-25,-69,-26,11,-11,-7,11,-36,-5,-17,-30,0,-28,32,-32,-20,-36,79,-16,8,70,-90,-33,20,36,79,39,13,19,29,-46, 72,-67,-29,-71,8,-36,22,-10,26,-37,-91,42,-96,-97,-54,-40,-45,22,-53,40,-7,-78,-3,-4,-20,-39,79,16,-99,5,-16,-57,74,-3,-21,-5,40,-25,47,72,-24,127,-31,9,-84,25,-58,-112,-74,38,3,-47,-66,12,51,19,-108,-44,4,-55,45,-15,58,-50,-14, 
  /* [6][0][][] */ -57,11,14,-39,25,-96,-48,-127,14,-16,28,-35,-9,93,-22,7,45,-70,-8,-118,-50,-52,55,-54,82,8,-48,-49,-65,15,-65,-26,8,-18,-41,-24,-84,-6,-19,-30,-33,-69,34,-5,-39,67,-36,-3,-18,-15,-24,-44,-71,23,-69,14,-50,-38,-21,8,2,40,-80,-37,-25, -47,27,65,47,-9,-5,24,19,-48,-33,35,21,24,72,-14,16,15,7,-2,40,37,40,-14,40,-56,-15,10,3,-29,51,-106,-1,-25,-9,-33,-16,94,-3,-15,22,-58,49,6,-39,-51,-22,-16,-32,62,14,-26,13,-25,5,-31,31,19,-6,7,81,-28,17,-11,75,65, -87,-76,6,-40,-56,15,34,-41,-11,-30,20,5,9,-98,-28,-72,13,-15,-63,40,-75,25,-15,-16,86,79,-50,-55,-52,-25,8,-62,45,-46,-44,-35,-89,32,20,-72,-8,-86,-27,-78,-3,-120,109,23,-64,66,36,13,9,11,-14,-89,62,4,-103,-10,-123,-109,-21,-43,-51, 
  /* [7][0][][] */ 55,-62,-2,-29,-29,-71,-11,-26,-48,44,-65,-37,-17,2,-47,-30,1,69,-2,-22,29,-42,10,-57,-5,-19,-69,-8,-38,-95,-14,4,26,18,-42,-23,-27,27,16,-11,26,-83,-30,-31,-16,64,-46,11,-93,36,19,1,51,45,-62,-64,8,-26,-47,-84,63,-24,-15,-101,-14, -7,-57,-52,25,-14,-62,22,-70,-15,-62,-30,30,-3,84,-23,6,36,-21,11,30,14,25,-45,-15,-9,26,28,30,-12,24,74,-61,-47,3,7,-74,-51,37,-46,-12,-10,-82,-51,-68,38,-14,-7,72,105,1,41,33,40,18,43,-26,25,-61,31,-57,20,85,-43,-18,55, 70,12,-24,-49,-26,-95,-105,50,-15,52,8,-19,21,-43,103,-9,-18,7,26,-17,-7,-20,8,0,-57,28,-4,0,62,18,18,64,-44,-14,-73,63,-54,-15,14,-61,38,-38,-62,-8,-69,-15,-36,-30,1,-71,-60,38,-28,-96,-53,-25,50,40,25,-47,34,-127,26,33,73, 
};
const TfArray<4, int> tensor_dimension11 = { 4, { 8,1,3,65 } };
const TfArray<8, float> quant11_scale = { 8, { 0.011756334453821182, 0.017703264951705933, 0.016994737088680267, 0.017304152250289917, 0.019234417006373405, 0.015081685036420822, 0.016836203634738922, 0.016901835799217224, } };
const TfArray<8, int> quant11_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,99,65 } };
const TfArray<1, float> quant12_scale = { 1, { 0.0095718381926417351, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,99,8 } };
const TfArray<1, float> quant13_scale = { 1, { 0.16103418171405792, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,99,1,8 } };
const TfArray<1, float> quant14_scale = { 1, { 0.16103418171405792, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,50,1,8 } };
const TfArray<1, float> quant15_scale = { 1, { 0.16103418171405792, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,50,8 } };
const TfArray<1, float> quant16_scale = { 1, { 0.16103418171405792, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,50,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.034876763820648193, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,50,1,16 } };
const TfArray<1, float> quant18_scale = { 1, { 0.034876763820648193, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant19_scale = { 1, { 0.034876763820648193, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,400 } };
const TfArray<1, float> quant20_scale = { 1, { 0.034876763820648193, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,2 } };
const TfArray<1, float> quant21_scale = { 1, { 0.43563798069953918, } };
const TfArray<1, int> quant21_zero = { 1, { 3 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,2 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,11,10 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,9,8 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,7,6 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
};

TensorInfo_t tensorData[] = {
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 6448), (TfLiteIntArray*)&g0::tensor_dimension0, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data1, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data2, (TfLiteIntArray*)&g0::tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data3, (TfLiteIntArray*)&g0::tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data4, (TfLiteIntArray*)&g0::tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data5, (TfLiteIntArray*)&g0::tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data6, (TfLiteIntArray*)&g0::tensor_dimension6, 8, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant6))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data7, (TfLiteIntArray*)&g0::tensor_dimension7, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant7))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data8, (TfLiteIntArray*)&g0::tensor_dimension8, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant8))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data9, (TfLiteIntArray*)&g0::tensor_dimension9, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant9))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data10, (TfLiteIntArray*)&g0::tensor_dimension10, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant10))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data11, (TfLiteIntArray*)&g0::tensor_dimension11, 1560, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant11))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension12, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant12))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 6448), (TfLiteIntArray*)&g0::tensor_dimension13, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant13))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension14, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant14))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension15, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant15))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension16, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant16))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension17, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension18, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant18))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension19, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant19))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension20, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant20))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 400), (TfLiteIntArray*)&g0::tensor_dimension21, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension22, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant22))}, },
};

#ifndef TF_LITE_STATIC_MEMORY
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#else
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#endif

used_operators_e used_ops[] =
{OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX, };


// Indices into tflTensors and tflNodes for subgraphs
const size_t tflTensors_subgraph_index[] = {0, 23, };
const size_t tflNodes_subgraph_index[] = {0, 11, };

// Input/output tensors
static const int in_tensor_indices[] = {
  0, 
};

static const int out_tensor_indices[] = {
  22, 
};


size_t current_subgraph_index = 0;

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = false;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}

typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;

static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
 
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  }

  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }

  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }
 
  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }

  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }

  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }

};


} // namespace

TfLiteStatus tflite_learn_5_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  
  // Set microcontext as the context ptr
  ctx.impl_ = static_cast<void*>(&micro_context_);
  // Setup tflitecontext functions
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;

  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }

  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].init) {
        tflNodes[i].user_data = registrations[used_ops[i]].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
      }
    }
  }
  current_subgraph_index = 0;

  for(size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].prepare) {
        ResetTensors();
        TfLiteStatus status = registrations[used_ops[i]].prepare(&ctx, &tflNodes[i]);
        if (status != kTfLiteOk) {
          return status;
        }
      }
    }
  }
  current_subgraph_index = 0;

  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(in_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(out_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[used_ops[i]].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
